#!/usr/bin/env python
# coding=utf-8

"""This script put initial crawler links to rabbitmq `http_request` queue.


Usage:

>>> yascrapy_producer -n producer -c 10

You have to ensure `producer.py` is in current directory.
"""

import importlib
from optparse import OptionParser
import multiprocessing
import sys
import os


def input_params():
    parser = OptionParser()
    parser.add_option(
        "-c", "--count", dest="count", type=int, help="specify worker count", default=1)
    parser.add_option(
        "-n", "--name", dest="name", type=str, help="specify producer name")
    parser.add_option("-f", "--conf", dest="config_file", type=str,
                      help="specify config file", default="/etc/yascrapy/common.json")
    (options, args) = parser.parse_args()
    return (options, args)


def main():
    (options, args) = input_params()
    try:
        module = importlib.import_module(options.name)
    except Exception:
        print "[error] producer name error, ensure producer module exsits in current directory."
        traceback.print_exc()
        return
    process_list = []
    for i in range(options.count):
        p = module.Producer(
            producers=options.count,
            producer_index=i + 1,
            config_file=options.config_file,
            settings=module.settings
        )
        process = multiprocessing.Process(target=p.run)
        process_list.append(process)
        process.start()
    for p in process_list:
        p.join()


if __name__ == "__main__":
    import traceback
    current_dir = os.getcwd()
    sys.path.append(current_dir)
    main()
