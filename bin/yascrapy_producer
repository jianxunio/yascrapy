#!/usr/bin/env python
# coding=utf-8

"""This script put initial crawler links to rabbitmq `http_request` queue.


Usage:

>>> yascrapy_producer -n producer

You have to ensure `producer.py` is in current directory.
"""

import importlib
from optparse import OptionParser
import multiprocessing
import sys
import os


def input_params():
    parser = OptionParser()
    parser.add_option(
        "-c", "--count",
        dest="count",
        type=int,
        help="specify worker count",
        default=1
    )
    parser.add_option(
        "-n", "--name", dest="name", type=str, help="specify producer name")
    parser.add_option(
        "-f", "--conf",
        dest="config_file", type=str,
        help="specify config file", default="/etc/yascrapy/common.json")
    (options, args) = parser.parse_args()
    return (options, args)


def main():
    (options, args) = input_params()
    try:
        module = importlib.import_module(options.name)
    except Exception:
        print ("[error] producer name error, "
        "ensure producer module exsits in current directory.")
        traceback.print_exc()
        return
    process_list = []
    for i in range(options.count):
        p = module.Producer(
            producers=options.count,
            producer_index=i + 1,
            config_file=options.config_file,
            settings=module.settings
        )
        process = multiprocessing.Process(target=p.run)
        process_list.append(process)
        process.start()
    for p in process_list:
        p.join()


if __name__ == "__main__":
    import traceback
    current_dir = os.getcwd()
    sys.path.append(current_dir)
    main()
